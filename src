import os
import math
import numpy as np
from Bio import SeqIO
from collections import defaultdict
from multiprocessing import Pool, cpu_count

# Constants
STR_BASE = "-base"
STR_INPUT = "-input"
STR_OUTPUT = "-output"
STR_KMER = "-kmer"
STR_PAIR1 = "-pair1"
STR_PAIR2 = "-pair2"
STR_SORTING = "-sorting"
STR_KSORTING = "-ksorting"
STR_BSIZE = "-binsize"
COLL_STAT = "-cs"
STR_TYPE = "-type"

# Function to generate k-mers from a sequence
def generate_kmers(seq, kmer_size):
    return [seq[i:i+kmer_size] for i in range(len(seq) - kmer_size + 1)]

# Function to construct a de Bruijn graph from sequences
def construct_debruijn_graph(seqs, kmer_size):
    graph = defaultdict(list)
    
    for seq in seqs:
        kmers = generate_kmers(seq, kmer_size)
        for i in range(len(kmers) - 1):
            node_from = kmers[i]
            node_to = kmers[i + 1]
            graph[node_from].append(node_to)
    
    return graph

# Function to traverse the de Bruijn graph and compute median abundance
def traverse_debruijn_graph(graph, seq, kmer_size, nodeit):
    read_abundance = 0
    abdce = []
    kmers = generate_kmers(seq, kmer_size)
    
    for kmer in kmers:
        if kmer in graph:
            node = kmer
            index = nodeit[node]
            abund = nodeit[index]
            abdce.append(abund)
    
    abdce.sort()
    i = len(abdce)
    
    if i % 2 == 0:
        median = (abdce[i // 2] + abdce[i // 2 - 1]) / 2
    else:
        median = abdce[i // 2]
    
    return median

# Function to calculate quality
def calculate_quality(qual):
    return sum(ord(c) for c in qual)

# Function to check read acceptance
def read_acceptance(graph, seq, kmer_size, counter, base, nodeit):
    kmers = generate_kmers(seq, kmer_size)
    
    for kmer in kmers:
        if kmer in graph:
            node = kmer
            index = nodeit[node]
            abund = nodeit[index]
            
            threshold = math.ceil(math.log(abund) / math.log(base))
            if threshold > abund:
                threshold = abund
            if threshold < 1:
                threshold = 1
            
            if counter[index] < threshold:
                return True
    
    return False

# Function to process single-end reads
def process_single_end(args):
    seqs, filename, out_file, base, kmer_size, seq_type, nodeit = args
    counter = defaultdict(int)
    out_dataset = []
    
    if seq_type.lower() in ["fastq", "fq"]:
        extension = ".fq"
    else:
        extension = ".fa"
    
    out_file1 = out_file + extension
    
    graph = construct_debruijn_graph(seqs, kmer_size)
    
    with open(filename, "r") as f:
        for record in SeqIO.parse(f, seq_type):
            if read_acceptance(graph, record.seq, kmer_size, counter, base, nodeit):
                out_dataset.append(record)
    
    SeqIO.write(out_dataset, out_file1, seq_type)
    print(f"Kept {len(out_dataset)} reads")

# Main execution
if __name__ == "__main__":
    # Replace these paths with your input files
    input_file = "input.fasta"
    output_file = "output.fasta"
    
    # Parameters
    base = 10  # Base for log calculation
    kmer_size = 31  # K-mer size
    seq_type = "fasta"  # Input sequence type ("fasta" or "fastq")
    
    # Placeholder for nodeit (replace with your actual data)
    nodeit = defaultdict(int)  # Example data
    
    # Create a multiprocessing pool
    num_cores = min(cpu_count(), 8)  # Use up to 8 cores
    pool = Pool(num_cores)
    
    # Load sequences from input file
    seqs = [str(record.seq) for record in SeqIO.parse(input_file, seq_type)]
    
    # Define arguments for the process_single_end function
    args_list = [(seqs, input_file, output_file, base, kmer_size, seq_type, nodeit) for _ in range(num_cores)]
    
    # Process the single-end reads in parallel
    pool.map(process_single_end, args_list)
    
    # Close the multiprocessing pool
    pool.close()
    pool.join()
